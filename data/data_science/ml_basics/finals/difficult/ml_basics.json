{
  "subtopic_id": "ml_basics",
  "subtopic_name": "Machine Learning Basics",
  "mode": "finals",
  "difficulty": "difficult",
  "questions": [
    {
      "question": "What is machine learning?",
      "answer": "A subset of AI where systems learn from data to improve performance without explicit programming",
      "alternatives": [],
      "explanation": "Machine learning is a subset of artificial intelligence focused on building systems that learn from data to improve performance on tasks without being explicitly programmed for every scenario. Instead of writing rules (if-then), ML algorithms identify patterns in training data and make predictions on new data. Key aspects: learning from experience (data), generalizing to unseen examples, improving with more data. Arthur Samuel (1959): 'Field of study that gives computers the ability to learn without being explicitly programmed.'"
    },
    {
      "question": "What is the difference between supervised and unsupervised learning?",
      "answer": "Supervised learns from labeled data (input-output pairs); unsupervised finds patterns in unlabeled data",
      "alternatives": [],
      "explanation": "Supervised learning trains on labeled data where each input has a corresponding correct output (target). Goal: learn mapping from inputs to outputs for predictions on new data. Examples: classification (spam/not spam), regression (house price prediction). Algorithms: linear regression, decision trees, neural networks. Unsupervised learning works with unlabeled data to discover hidden patterns or structures. Goal: find natural groupings or representations. Examples: clustering (customer segmentation), dimensionality reduction (PCA). Algorithms: K-means, hierarchical clustering, autoencoders."
    },
    {
      "question": "What is overfitting in machine learning?",
      "answer": "When a model learns training data too well, including noise, resulting in poor generalization to new data",
      "alternatives": [],
      "explanation": "Overfitting occurs when a model learns the training data too well, memorizing patterns, noise, and outliers rather than learning the underlying general pattern. Result: excellent training performance but poor performance on new/test data (low generalization). Causes: model too complex, insufficient training data, training too long, noise in data. Solutions: regularization (L1/L2), cross-validation, more training data, simpler models, dropout (neural networks), early stopping, pruning (decision trees). Opposite: underfitting (model too simple to capture patterns)."
    },
    {
      "question": "What is the purpose of splitting data into training, validation, and test sets?",
      "answer": "Training: learn model; Validation: tune hyperparameters; Test: final unbiased evaluation",
      "alternatives": [],
      "explanation": "Data is split into three sets for proper ML development: (1) Training set (60-80%): used to train/fit the model parameters, (2) Validation set (10-20%): used during development to tune hyperparameters, compare models, make decisions (model selection, early stopping), (3) Test set (10-20%): held out until final evaluation to provide unbiased assessment of model generalization. Test set simulates real-world deployment. Never use test data for any training decisions. Common splits: 70-15-15, 80-10-10. Cross-validation is alternative for small datasets."
    },
    {
      "question": "What is cross-validation?",
      "answer": "A resampling technique that divides data into folds, training on some and validating on others iteratively to assess model performance",
      "alternatives": [],
      "explanation": "Cross-validation is a resampling technique for assessing model performance by dividing data into k subsets (folds), training on k-1 folds and validating on the remaining fold, repeating k times so each fold serves as validation once. Final score is the average across all folds. K-fold CV (typically k=5 or k=10) provides more reliable performance estimates than single train-test split, especially with limited data. Benefits: uses all data for both training and validation, reduces variance in performance estimates. Stratified CV maintains class distributions. Leave-One-Out CV: k=n (one sample per fold)."
    },
    {
      "question": "What is the bias-variance tradeoff?",
      "answer": "A tradeoff between underfitting (high bias) and overfitting (high variance) when selecting model complexity",
      "alternatives": [],
      "explanation": "The bias-variance tradeoff describes the balance between two sources of error: (1) Bias: error from overly simplistic models that underfit (high bias → underfitting, missed patterns), (2) Variance: error from overly complex models sensitive to training data fluctuations (high variance → overfitting, learning noise). Total error = Bias² + Variance + Irreducible Error. Simple models: high bias, low variance. Complex models: low bias, high variance. Goal: find sweet spot minimizing total error. Techniques: regularization, ensemble methods (bagging reduces variance, boosting reduces bias)."
    },
    {
      "question": "What is a confusion matrix?",
      "answer": "A table showing True Positives, True Negatives, False Positives, and False Negatives to evaluate classification performance",
      "alternatives": [],
      "explanation": "A confusion matrix is a table summarizing classification performance by comparing predicted vs. actual classes. For binary classification: True Positive (TP): correctly predicted positive, True Negative (TN): correctly predicted negative, False Positive (FP, Type I error): incorrectly predicted positive, False Negative (FN, Type II error): incorrectly predicted negative. From this, calculate metrics: Accuracy = (TP+TN)/Total, Precision = TP/(TP+FP), Recall/Sensitivity = TP/(TP+FN), Specificity = TN/(TN+FP), F1-Score = 2×(Precision×Recall)/(Precision+Recall). Essential for evaluating classifiers beyond accuracy, especially with imbalanced datasets."
    },
    {
      "question": "What is feature engineering?",
      "answer": "The process of creating, transforming, or selecting features from raw data to improve model performance",
      "alternatives": [],
      "explanation": "Feature engineering is the process of creating, transforming, or selecting relevant features (input variables) from raw data to improve ML model performance. Techniques: (1) Creation: polynomial features, interaction terms, domain-specific features (from date: day_of_week, is_weekend), (2) Transformation: log/square root (for skewed data), binning/discretization, (3) Selection: removing irrelevant/redundant features, (4) Extraction: PCA, text embeddings. Often more impactful than algorithm choice. Requires domain knowledge. 'Applied machine learning is basically feature engineering' - Andrew Ng."
    },
    {
      "question": "What is regularization?",
      "answer": "A technique to prevent overfitting by adding a penalty term to the loss function to constrain model complexity",
      "alternatives": [],
      "explanation": "Regularization prevents overfitting by adding a penalty term to the loss function that discourages overly complex models (large weights). Types: (1) L1 regularization (Lasso): penalty = λ Σ|wi|, promotes sparsity (feature selection), drives some weights to zero, (2) L2 regularization (Ridge): penalty = λ Σwi², shrinks weights toward zero but not exactly zero, more stable, (3) Elastic Net: combines L1 and L2. Hyperparameter λ (lambda) controls regularization strength: higher λ = more regularization. Also used in neural networks (weight decay). Tradeoff: prevents overfitting but may increase bias."
    },
    {
      "question": "What is the difference between classification and regression?",
      "answer": "Classification predicts discrete categories/classes; regression predicts continuous numerical values",
      "alternatives": [],
      "explanation": "Classification and regression are two main types of supervised learning tasks: Classification predicts discrete categories or classes (categorical output). Types: binary (2 classes: spam/not spam), multi-class (>2 classes: cat/dog/bird), multi-label (multiple categories per instance). Algorithms: Logistic Regression, Decision Trees, SVM, Neural Networks. Metrics: accuracy, precision, recall, F1-score. Regression predicts continuous numerical values (quantitative output). Examples: house price, temperature, stock price. Algorithms: Linear Regression, Polynomial Regression, SVR, Neural Networks. Metrics: MSE, RMSE, MAE, R². Some algorithms do both: decision trees, neural networks."
    }
  ]
}