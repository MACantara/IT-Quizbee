{
  "subtopic_id": "statistics",
  "subtopic_name": "Statistics",
  "mode": "finals",
  "difficulty": "average",
  "questions": [
    {
      "question": "What test determines if differences between groups are statistically significant?",
      "answer": "Hypothesis test",
      "alternatives": [
        "Statistical significance test"
      ],
      "explanation": "Hypothesis testing evaluates whether observed differences are likely due to chance or represent real effects. It involves null hypothesis (no effect), alternative hypothesis (effect exists), and calculating probability (p-value) of observing the data if null is true. P < 0.05 typically indicates statistical significance."
    },
    {
      "question": "What is the probability of rejecting a true null hypothesis?",
      "answer": "Type I error",
      "alternatives": [
        "False positive",
        "Alpha error"
      ],
      "explanation": "Type I error (false positive) occurs when we conclude an effect exists when it doesn't. The significance level (α, typically 0.05) is the acceptable Type I error rate. For example, claiming a drug works when it doesn't. Lowering α reduces Type I errors but increases Type II errors."
    },
    {
      "question": "What measure indicates strength and direction of linear relationship between variables?",
      "answer": "Correlation coefficient",
      "alternatives": [
        "Pearson correlation"
      ],
      "explanation": "The correlation coefficient (r) measures linear relationship strength and direction between two variables, ranging from -1 (perfect negative) to +1 (perfect positive). Zero indicates no linear relationship. Correlation doesn't imply causation - correlated variables may share a common cause or correlation may be coincidental."
    },
    {
      "question": "What statistical technique models relationship between dependent and independent variables?",
      "answer": "Regression analysis",
      "alternatives": [
        "Regression"
      ],
      "explanation": "Regression analysis models relationships between variables to predict outcomes. Linear regression fits a line to data; multiple regression uses several predictors. Regression provides coefficients showing each variable's effect, and R² indicating model fit. It's used for prediction, understanding relationships, and testing hypotheses."
    },
    {
      "question": "What distribution models the number of events in a fixed interval?",
      "answer": "Poisson distribution",
      "alternatives": [
        "Poisson"
      ],
      "explanation": "Poisson distribution models count of events occurring in fixed intervals of time or space when events happen independently at a constant rate. Examples include customer arrivals per hour, defects per unit, or emails per day. It's characterized by parameter λ (lambda), the average rate of occurrence."
    },
    {
      "question": "What sampling method divides population into subgroups and samples from each?",
      "answer": "Stratified sampling",
      "alternatives": [
        "Stratified random sampling"
      ],
      "explanation": "Stratified sampling divides the population into homogeneous subgroups (strata) based on characteristics, then randomly samples from each stratum. This ensures representation of all subgroups and can improve precision compared to simple random sampling. Proportional allocation maintains population proportions; equal allocation samples equally from each stratum."
    },
    {
      "question": "What measure is unaffected by extreme values in the data?",
      "answer": "Robust statistic",
      "alternatives": [
        "Resistant measure"
      ],
      "explanation": "Robust statistics resist influence of outliers and extreme values. Median is robust (unlike mean); interquartile range is robust (unlike range); median absolute deviation is robust (unlike standard deviation). Robust measures provide more reliable estimates for skewed or contaminated data."
    },
    {
      "question": "What describes the shape of probability distribution tails?",
      "answer": "Kurtosis",
      "alternatives": [
        "Tail heaviness"
      ],
      "explanation": "Kurtosis measures tail heaviness and peakedness of distributions. High kurtosis (leptokurtic) indicates heavy tails and sharp peak; low kurtosis (platykurtic) indicates light tails and flat peak. Normal distribution has kurtosis of 3. Excess kurtosis subtracts 3, making normal distribution have excess kurtosis of 0."
    },
    {
      "question": "What indicates whether distribution is symmetric or leans to one side?",
      "answer": "Skewness",
      "alternatives": [
        "Asymmetry"
      ],
      "explanation": "Skewness measures distribution asymmetry. Positive skew (right-skewed) has a long right tail; negative skew (left-skewed) has a long left tail. Zero skewness indicates symmetry. In right-skewed data, mean > median > mode. Income distributions are typically right-skewed with few extremely high values."
    },
    {
      "question": "What theorem states that sample means approach normal distribution as sample size increases?",
      "answer": "Central Limit Theorem",
      "alternatives": [
        "CLT"
      ],
      "explanation": "The Central Limit Theorem (CLT) states that regardless of population distribution, the distribution of sample means approaches normality as sample size increases (typically n ≥ 30). This is why normal distribution is so important - it justifies using normal-based inference methods even when underlying data isn't normal."
    }
  ]
}