{
  "subtopic_id": "ml_basics",
  "subtopic_name": "Machine Learning Basics",
  "mode": "finals",
  "difficulty": "difficult",
  "questions": [
    {
      "question": "What technique transfers knowledge from one domain to another?",
      "answer": "Transfer learning",
      "alternatives": [],
      "explanation": "Transfer learning reuses pretrained models for new but related tasks."
    },
    {
      "question": "What optimization algorithm adapts learning rates per parameter?",
      "answer": "Adam",
      "alternatives": ["Adaptive Moment Estimation"],
      "explanation": "Adam combines momentum and adaptive learning rates for efficient training."
    },
    {
      "question": "What method evaluates feature importance through permutation?",
      "answer": "Permutation importance",
      "alternatives": [],
      "explanation": "Permutation importance shuffles features to measure impact on performance."
    },
    {
      "question": "What technique handles missing data using model predictions?",
      "answer": "Multiple imputation",
      "alternatives": ["MICE"],
      "explanation": "Multiple imputation generates plausible values for missing entries."
    },
    {
      "question": "What combines L1 and L2 regularization?",
      "answer": "Elastic Net",
      "alternatives": ["ElasticNet"],
      "explanation": "Elastic Net balances feature selection and coefficient shrinkage."
    },
    {
      "question": "What metric evaluates ranking quality for binary classification?",
      "answer": "AUC-ROC",
      "alternatives": ["AUC", "Area Under Curve"],
      "explanation": "AUC-ROC measures the model's ability to distinguish between classes."
    },
    {
      "question": "What technique reduces variance by averaging bootstrap samples?",
      "answer": "Bagging",
      "alternatives": ["Bootstrap aggregating"],
      "explanation": "Bagging creates multiple models on random subsets and averages results."
    },
    {
      "question": "What sequentially builds models to correct previous errors?",
      "answer": "Boosting",
      "alternatives": ["Gradient boosting"],
      "explanation": "Boosting focuses on hard-to-predict examples in successive iterations."
    },
    {
      "question": "What hyperparameter controls model complexity in tree-based methods?",
      "answer": "Max depth",
      "alternatives": ["Maximum depth", "Tree depth"],
      "explanation": "Max depth limits how deep decision trees can grow."
    },
    {
      "question": "What approach combines labeled and unlabeled data for training?",
      "answer": "Semi-supervised learning",
      "alternatives": ["Semi supervised learning"],
      "explanation": "Semi-supervised learning leverages both labeled and unlabeled examples."
    }
  ]
}