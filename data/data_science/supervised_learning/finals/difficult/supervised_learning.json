{
  "subtopic_id": "supervised_learning",
  "subtopic_name": "Supervised Learning",
  "mode": "finals",
  "difficulty": "difficult",
  "questions": [
    {
      "question": "What boosting library uses histogram-based learning?",
      "answer": "LightGBM",
      "alternatives": [
        "Light GBM"
      ],
      "explanation": "LightGBM speeds up training with histogram-based algorithms.",
      "id": "sup_lea_sup_lea_d_finals_000"
    },
    {
      "question": "What SVM kernel handles non-linear boundaries efficiently?",
      "answer": "RBF kernel",
      "alternatives": [
        "Radial Basis Function",
        "Gaussian kernel"
      ],
      "explanation": "RBF kernel maps features to infinite-dimensional space.",
      "id": "sup_lea_sup_lea_d_finals_001"
    },
    {
      "question": "What technique stacks model predictions as meta-features?",
      "answer": "Stacking",
      "alternatives": [
        "Stacked generalization"
      ],
      "explanation": "Stacking trains a meta-model on predictions from base models.",
      "id": "sup_lea_sup_lea_d_finals_002"
    },
    {
      "question": "What decision tree criterion measures information gain?",
      "answer": "Entropy",
      "alternatives": [
        "Information entropy"
      ],
      "explanation": "Entropy quantifies uncertainty used in ID3 and C4.5 algorithms.",
      "id": "sup_lea_sup_lea_d_finals_003"
    },
    {
      "question": "What gradient boosting variant uses second-order derivatives?",
      "answer": "XGBoost",
      "alternatives": [
        "Extreme Gradient Boosting"
      ],
      "explanation": "XGBoost uses Newton-Raphson method for optimization.",
      "id": "sup_lea_sup_lea_d_finals_004"
    },
    {
      "question": "What handles multi-class classification in SVM?",
      "answer": "One-vs-Rest",
      "alternatives": [
        "OvR",
        "One-vs-All"
      ],
      "explanation": "One-vs-Rest trains binary classifiers for each class.",
      "id": "sup_lea_sup_lea_d_finals_005"
    },
    {
      "question": "What algorithm optimizes hyperplanes with slack variables?",
      "answer": "Soft-margin SVM",
      "alternatives": [
        "Soft margin SVM"
      ],
      "explanation": "Soft-margin SVM allows some misclassifications for better generalization.",
      "id": "sup_lea_sup_lea_d_finals_006"
    },
    {
      "question": "What regression handles multiple outputs simultaneously?",
      "answer": "Multi-output regression",
      "alternatives": [
        "Multioutput regression"
      ],
      "explanation": "Multi-output regression predicts multiple target variables jointly.",
      "id": "sup_lea_sup_lea_d_finals_007"
    },
    {
      "question": "What boosting technique uses categorical features natively?",
      "answer": "CatBoost",
      "alternatives": [
        "Cat Boost"
      ],
      "explanation": "CatBoost handles categorical data without preprocessing.",
      "id": "sup_lea_sup_lea_d_finals_008"
    },
    {
      "question": "What loss function is used for probabilistic regression?",
      "answer": "Log loss",
      "alternatives": [
        "Cross-entropy",
        "Logarithmic loss"
      ],
      "explanation": "Log loss penalizes confident wrong predictions heavily.",
      "id": "sup_lea_sup_lea_d_finals_009"
    }
  ]
}