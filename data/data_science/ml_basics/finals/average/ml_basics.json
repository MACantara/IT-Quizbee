{
  "subtopic_id": "ml_basics",
  "subtopic_name": "Machine Learning Basics",
  "mode": "finals",
  "difficulty": "average",
  "questions": [
    {
      "question": "What metric balances precision and recall?",
      "answer": "F1-score",
      "alternatives": [
        "F1 score",
        "F1"
      ],
      "explanation": "F1-score is the harmonic mean of precision and recall.",
      "id": "ml_bas_ml_bas_a_finals_000"
    },
    {
      "question": "What is the ratio of true positives to all predicted positives?",
      "answer": "Precision",
      "alternatives": [],
      "explanation": "Precision measures the accuracy of positive predictions.",
      "id": "ml_bas_ml_bas_a_finals_001"
    },
    {
      "question": "What metric shows the ratio of true positives to all actual positives?",
      "answer": "Recall",
      "alternatives": [
        "Sensitivity",
        "True Positive Rate"
      ],
      "explanation": "Recall measures how many actual positives were correctly identified.",
      "id": "ml_bas_ml_bas_a_finals_002"
    },
    {
      "question": "What occurs when a model is too simple to capture patterns?",
      "answer": "Underfitting",
      "alternatives": [
        "Underfit"
      ],
      "explanation": "Underfitting results from insufficient model complexity.",
      "id": "ml_bas_ml_bas_a_finals_003"
    },
    {
      "question": "What method combines predictions from multiple models?",
      "answer": "Ensemble learning",
      "alternatives": [
        "Ensemble methods",
        "Ensembling"
      ],
      "explanation": "Ensemble learning aggregates multiple models for better performance.",
      "id": "ml_bas_ml_bas_a_finals_004"
    },
    {
      "question": "What type of regularization adds L1 penalty to the loss function?",
      "answer": "Lasso",
      "alternatives": [
        "L1 regularization"
      ],
      "explanation": "Lasso regression performs feature selection through L1 penalty.",
      "id": "ml_bas_ml_bas_a_finals_005"
    },
    {
      "question": "What type of regularization adds L2 penalty to the loss function?",
      "answer": "Ridge",
      "alternatives": [
        "L2 regularization"
      ],
      "explanation": "Ridge regression uses L2 penalty to reduce coefficient magnitudes.",
      "id": "ml_bas_ml_bas_a_finals_006"
    },
    {
      "question": "What learning paradigm uses rewards and penalties?",
      "answer": "Reinforcement learning",
      "alternatives": [
        "Reinforcement"
      ],
      "explanation": "Reinforcement learning trains agents through trial and error.",
      "id": "ml_bas_ml_bas_a_finals_007"
    },
    {
      "question": "What technique creates synthetic training examples?",
      "answer": "Data augmentation",
      "alternatives": [],
      "explanation": "Data augmentation expands training data through transformations.",
      "id": "ml_bas_ml_bas_a_finals_008"
    },
    {
      "question": "What is the process of selecting important features called?",
      "answer": "Feature selection",
      "alternatives": [],
      "explanation": "Feature selection identifies the most relevant variables for modeling.",
      "id": "ml_bas_ml_bas_a_finals_009"
    }
  ]
}