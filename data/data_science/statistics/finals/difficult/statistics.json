{
  "subtopic_id": "statistics",
  "subtopic_name": "Statistics",
  "mode": "finals",
  "difficulty": "difficult",
  "questions": [
    {
      "question": "What Bayesian concept updates probability based on new evidence?",
      "answer": "Posterior probability",
      "alternatives": [
        "Updated probability"
      ],
      "explanation": "Posterior probability is the updated probability after considering new evidence, calculated using Bayes' theorem: P(H|E) = P(E|H) × P(H) / P(E). It combines prior probability (initial belief) with likelihood (evidence fit) to produce posterior probability (updated belief). Bayesian inference iteratively updates beliefs as new data arrives."
    },
    {
      "question": "What resampling technique estimates sampling distribution by repeatedly sampling from data?",
      "answer": "Bootstrap",
      "alternatives": [
        "Bootstrapping"
      ],
      "explanation": "Bootstrap is a resampling method that repeatedly samples with replacement from observed data to estimate sampling distributions and calculate confidence intervals without distributional assumptions. By creating thousands of resamples, bootstrap approximates what would happen with repeated sampling from the population, providing robust uncertainty estimates."
    },
    {
      "question": "What technique tests multiple hypotheses while controlling false discovery rate?",
      "answer": "Multiple testing correction",
      "alternatives": [
        "Bonferroni correction",
        "FDR correction"
      ],
      "explanation": "Multiple testing correction adjusts significance thresholds when testing many hypotheses simultaneously to control false positives. Bonferroni correction divides α by number of tests (conservative); False Discovery Rate (FDR) methods like Benjamini-Hochberg are less conservative. Without correction, testing 100 hypotheses at α=0.05 expects 5 false positives by chance."
    },
    {
      "question": "What distribution models time between events in a Poisson process?",
      "answer": "Exponential distribution",
      "alternatives": [
        "Exponential"
      ],
      "explanation": "The exponential distribution models waiting time between events in a Poisson process where events occur continuously and independently at constant rate. It's memoryless - past waiting doesn't affect future waiting time. Examples include time between customer arrivals, equipment failures, or radioactive decay. It's characterized by rate parameter λ."
    },
    {
      "question": "What statistical framework treats parameters as random variables with prior distributions?",
      "answer": "Bayesian statistics",
      "alternatives": [
        "Bayesian inference"
      ],
      "explanation": "Bayesian statistics treats unknown parameters as random variables with probability distributions expressing uncertainty. It combines prior knowledge (prior distribution) with data (likelihood) via Bayes' theorem to get posterior distribution. Unlike frequentist methods focusing on long-run frequencies, Bayesian methods provide probability statements about parameters directly."
    },
    {
      "question": "What method selects models balancing goodness of fit with complexity?",
      "answer": "AIC",
      "alternatives": [
        "Akaike Information Criterion"
      ],
      "explanation": "Akaike Information Criterion (AIC) balances model fit with complexity, penalizing additional parameters to prevent overfitting. Lower AIC indicates better model. AIC = 2k - 2ln(L), where k is parameters and L is likelihood. BIC (Bayesian Information Criterion) is similar but penalizes complexity more heavily. These help choose among competing models."
    },
    {
      "question": "What test compares distributions between two samples without assuming normal distribution?",
      "answer": "Mann-Whitney U test",
      "alternatives": [
        "Wilcoxon rank-sum test"
      ],
      "explanation": "The Mann-Whitney U test (or Wilcoxon rank-sum test) is a non-parametric test comparing two independent samples without assuming normality. It tests whether distributions differ by ranking all values and comparing rank sums. It's more robust than t-tests for non-normal or ordinal data but less powerful when normality holds."
    },
    {
      "question": "What process has independent increments and continuous sample paths?",
      "answer": "Brownian motion",
      "alternatives": [
        "Wiener process"
      ],
      "explanation": "Brownian motion (Wiener process) is a continuous stochastic process with independent normally distributed increments. It models random movement like stock prices or particle diffusion. Properties include continuity everywhere, differentiability nowhere, and quadratic variation proportional to time. It's fundamental to stochastic calculus and financial mathematics."
    },
    {
      "question": "What time series model combines autoregression and moving average components?",
      "answer": "ARIMA",
      "alternatives": [
        "Autoregressive Integrated Moving Average"
      ],
      "explanation": "ARIMA models forecast time series by combining AR (autoregressive - using past values), I (integrated - differencing for stationarity), and MA (moving average - using past errors). ARIMA(p,d,q) specifies order of each component. It's powerful for forecasting but requires stationary data and careful parameter selection. SARIMA adds seasonal components."
    },
    {
      "question": "What measures information gained from knowing one variable about another?",
      "answer": "Mutual information",
      "alternatives": [
        "Information gain"
      ],
      "explanation": "Mutual information quantifies the amount of information one variable provides about another, measuring dependence between variables. Unlike correlation (which captures only linear relationships), mutual information detects any type of dependence. It's based on entropy from information theory and is used in feature selection, variable importance, and causal inference."
    }
  ]
}