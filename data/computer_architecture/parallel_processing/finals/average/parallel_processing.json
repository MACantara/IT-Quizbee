{
  "subtopic_id": "parallel_processing",
  "subtopic_name": "Parallel Processing",
  "mode": "finals",
  "difficulty": "average",
  "questions": [
    {
      "question": "What law describes the maximum speedup from parallelization?",
      "answer": "Amdahl's Law",
      "alternatives": [
        "Amdahl"
      ],
      "explanation": "Amdahl's Law calculates theoretical speedup limit based on the fraction of code that can be parallelized.",
      "id": "par_pro_par_pro_a_finals_000"
    },
    {
      "question": "What metric measures how effectively processors are utilized in parallel computing?",
      "answer": "Parallel efficiency",
      "alternatives": [
        "Efficiency",
        "Processor efficiency"
      ],
      "explanation": "Parallel efficiency measures how effectively additional processors improve performance, calculated as speedup divided by number of processors.",
      "id": "par_pro_par_pro_a_finals_001"
    },
    {
      "question": "What error occurs when threads access shared data without synchronization?",
      "answer": "Race condition",
      "alternatives": [
        "Data race",
        "Race hazard"
      ],
      "explanation": "Race conditions occur when concurrent threads access shared data without proper synchronization, causing unpredictable results.",
      "id": "par_pro_par_pro_a_finals_002"
    },
    {
      "question": "What is a mutex?",
      "answer": "Mutual exclusion lock",
      "alternatives": [
        "Mutual exclusion",
        "Lock mechanism"
      ],
      "explanation": "A mutex prevents multiple threads from simultaneously accessing a shared resource.",
      "id": "par_pro_par_pro_a_finals_003"
    },
    {
      "question": "What condition occurs when threads wait for resources held by each other?",
      "answer": "Deadlock",
      "alternatives": [
        "Circular wait",
        "Resource deadlock"
      ],
      "explanation": "Deadlock occurs when threads are stuck waiting for resources held by each other, preventing any progress.",
      "id": "par_pro_par_pro_a_finals_004"
    },
    {
      "question": "What protocol ensures consistent cache values across multiple cores?",
      "answer": "Cache coherence",
      "alternatives": [
        "Cache consistency"
      ],
      "explanation": "Cache coherence ensures all processor cores see a consistent view of shared memory.",
      "id": "par_pro_par_pro_a_finals_005"
    },
    {
      "question": "What optimization converts scalar loops to SIMD operations?",
      "answer": "Vectorization",
      "alternatives": [
        "Vector processing",
        "SIMD optimization"
      ],
      "explanation": "Vectorization transforms scalar operations into vector operations that process multiple data elements simultaneously.",
      "id": "par_pro_par_pro_a_finals_006"
    },
    {
      "question": "What technique distributes work evenly across processors?",
      "answer": "Load balancing",
      "alternatives": [
        "Work distribution",
        "Task balancing"
      ],
      "explanation": "Load balancing ensures all processors have roughly equal amounts of work to maximize efficiency.",
      "id": "par_pro_par_pro_a_finals_007"
    },
    {
      "question": "What synchronization point forces all threads to wait before proceeding?",
      "answer": "Barrier",
      "alternatives": [
        "Synchronization barrier",
        "Barrier synchronization"
      ],
      "explanation": "A barrier forces all threads to reach a specific point before any can proceed further.",
      "id": "par_pro_par_pro_a_finals_008"
    },
    {
      "question": "What type of parallelism executes multiple independent threads simultaneously?",
      "answer": "Thread-level parallelism",
      "alternatives": [
        "TLP",
        "Thread parallelism"
      ],
      "explanation": "TLP exploits parallelism by running multiple independent threads simultaneously.",
      "id": "par_pro_par_pro_a_finals_009"
    }
  ]
}