{
  "subtopic_id": "supervised_learning",
  "subtopic_name": "Supervised Learning",
  "mode": "finals",
  "difficulty": "average",
  "questions": [
    {
      "question": "What boosting algorithm builds trees sequentially?",
      "answer": "Gradient Boosting",
      "alternatives": ["Gradient boosting", "GBM"],
      "explanation": "Gradient Boosting iteratively adds trees that correct previous errors."
    },
    {
      "question": "What metric represents the square root of MSE?",
      "answer": "RMSE",
      "alternatives": ["Root Mean Squared Error"],
      "explanation": "RMSE provides error measurement in the same units as the target variable."
    },
    {
      "question": "What SVM parameter controls the margin-error tradeoff?",
      "answer": "C parameter",
      "alternatives": ["C", "Regularization parameter"],
      "explanation": "The C parameter balances maximizing margin and minimizing errors."
    },
    {
      "question": "What technique transforms features for non-linear SVM?",
      "answer": "Kernel trick",
      "alternatives": ["Kernel method"],
      "explanation": "The kernel trick maps data to higher dimensions without explicit computation."
    },
    {
      "question": "What metric measures absolute average prediction error?",
      "answer": "MAE",
      "alternatives": ["Mean Absolute Error"],
      "explanation": "MAE calculates the average magnitude of errors without squaring."
    },
    {
      "question": "What prevents decision trees from growing too deep?",
      "answer": "Pruning",
      "alternatives": ["Tree pruning"],
      "explanation": "Pruning removes branches to prevent overfitting."
    },
    {
      "question": "What XGBoost feature handles missing values automatically?",
      "answer": "Sparse awareness",
      "alternatives": ["Sparsity awareness"],
      "explanation": "XGBoost learns optimal directions for missing values during training."
    },
    {
      "question": "What regression metric represents explained variance proportion?",
      "answer": "R-squared",
      "alternatives": ["R2", "Coefficient of determination"],
      "explanation": "R-squared indicates how well predictions match actual values."
    },
    {
      "question": "What distance metric does KNN commonly use?",
      "answer": "Euclidean distance",
      "alternatives": ["Euclidean"],
      "explanation": "Euclidean distance measures straight-line distance in feature space."
    },
    {
      "question": "What ensemble method trains models on bootstrap samples?",
      "answer": "Bagging",
      "alternatives": ["Bootstrap aggregating"],
      "explanation": "Bagging reduces variance by averaging predictions from resampled datasets."
    }
  ]
}